角色扮演有关的帖子

https://github.com/chg0901/Honor_of_Kings_Multi-modal_Dataset/blob/main/README.md

https://zhuanlan.zhihu.com/p/11295545591

https://zhuanlan.zhihu.com/p/719772276

https://mp.weixin.qq.com/s/3iacDV5vC5tq4rK6ZDuTiw

生成数据

生成数据比例
1.女生主动互动聊天阶段  （拓展男接话的能力）
2.女生对金钱的废物测试  （很重要 要学会破除废测）
3.女生需求感强 想找男聊天
4.生成的破冰数据 刚认识阶段 开头特点问：你是谁 
5.女借钱男高情商回应
6.男问女答的情况也有 作为开场白补充




数据清洗 构建jsonl数据 男主动数据3594条 + 之前女主动的4740 =8334条 还得去冗余
今天废了很大的劲生成了俩百条数据 数据这方面还是得研究 比如说一个prompt或者几个prompt怎么多样化的数据（思路用几个prompt生成种子数据 然后拿种子数据让其他模型进行仿写类似的对话  这个方法是数据合成 也可以对数据合成进行数据增强这样的话就能获得丰富的数据集了）


开场白数据生成（100条）扩增10倍

进一步提升刚接触时的聊天场景，增加了数据的多样性，因为要是直接prompt生成的话，效果肯定是不好的，有很多类似的对话，缺乏了多样性，开场白那就不一样了，模型很容易写这样的一句开场白的，然后根据开场白再续写下面的场景

开始合成350数据 小熊的数据还在做到时候打算直接扩增了


1.关于数据原本小熊9k男主动  加女主动Claude生成数据 3500条  加上后续扩增女主动 4.7k 加上男主动3.5k  数据量预估： 12500+4700+3500=20700 后续去冗余数据还会少
男主动目前 12.5k
女主动目前 8.2k

关于数据提升点：女生对金钱的废物测试 还有对高冷女的反应 男扩展延续话题能力增强  再提升了男主动发起邀约 被拒绝的情景


关于种子数据 可以参考角色扮演群里的思路 就是用dify精心构建prompt使用llm 对用户的第一句话进行扩展延伸 好拿到种子数据 这样方便调试  （慎用 比较原始 需要用户主动输入才能合成种子数据 可以找人搞 ）



数据增强、

数据质量控制：
设置合理的参数（如 alpha 值）
对增强后的文本进行质量筛选
可以使用语言模型评分筛选质量
多样性平衡：
混合使用多种增强方法
控制每种方法生成的数据比例
领域适应：
根据具体领域调整同义词库
添加领域特定的规则


可以使用语言模型评分筛选质量  这个的话要用gpt或者bert设置评估标准和打分机制 这样才能更好的为任务打分  做完可以过滤一些低评分的数据 再要细腻度话可以做去除冗余  数据去冗余不仅仅是去除简单的重复数据，还包括对语义重复、相似数据等的处理 去除完全重复数据 去除语义重复数据


写一个想法吧

最近在做关于角色扮演的多轮对话数据，真的感觉很有成就感的 关于数据这块有了一站式的思路了 比如关于种子数据生成，对于种子数据做合成，再对合成数据做增强，做数据处理，用GPT模型或者bert简单做个细粒度 然后可以进一步对数据做个细粒度清洗，使用data-juice进一步去除冗余，这样拿到的数据才是高质量的！！！

BERT/GPT初筛：去除明显的低质量样本
Data-juice精筛：进行更细致的质量控制


设置合理的过滤阈值
第一轮（BERT/GPT）：可以相对宽松，建议保留60-70%
第二轮（Data-juice）：可以更严格，建议保留50-60%
预期最终保留1.5k-2k条高质量数据
===================================================

关于主动学习的概念  这个方法适合就是现在有大量的数据 但是标注资源有限所以呢 采用主动学习的方法去找到最有价值的标注数据 进行人工标注
有什么意义呢  很有价值比如说主动学习后筛选出来的数据 可以作为种子数据进而生成新数据
==================================================
假设你有10000条客服对话，但只有资源标注1000条
这时主动学习就是帮你从这10000条中选择最有价值的1000条
"最有价值"通常指：
与已有数据差异大的（增加多样性）
模型最不确定的（有助于提升模型性能）
能代表某个类别的典型样本（提高代表性）
主动学习的常见场景：
数据标注场景
有大量未标注数据
标注资源有限
用主动学习选择最值得标注的样本
2. 数据集构建场景
有大量候选数据
需要构建一个较小但代表性强的子集
用主动学习选择最具代表性的样本
3. 模型训练场景
有限的训练资源
需要选择最有价值的训练样本
用主动学习选择最能提升模型性能的样本
你可能混淆的地方：
数据增强：创造新的数据
数据合成：生成新的数据
主动学习：选择已有数据中最有价值的部分

所以当我说"从高质量样本中选择多样化的子集"时，指的是：
先用质量评估筛选出高质量样本（比如从10000条中筛选出8000条）
再用主动学习从这8000条中选择最有价值的1000条
这1000条会是一个具有代表性和多样性的子集
====================================================================、、


重点！！！破冰数据 类似于女问问题后 男回答 女回复 哦 嗯 好 这时候必须补充这样的数据（好好想想要不要补充！）
这个也很重要：我觉得是女问完问题后 男回答接一句你呢 


还缺怎样的数据？？？

1.女间接性高冷 需要男热情幽默的来调动女生的情绪  这个至少一k条吧 俩k条
2.男问女答的数据 俩k条


计划数据处理计划: 
12.26周四 1.女间接性高冷 需要男热情幽默的来调动女生的情绪 200条种子数据 ---需要把男开头的开场白单独截取出来 存放
12.27周五 2.正常的男问女答的数据 200条种子数据 ---需要把男开头的开场白单独截取出来 存放
12.28周六 对400条种子数据进行扩充到4k条数据 

忘记了还得对数据进行增强

12.30周一 用bert或者gpt做细腻度过滤一些低质量数据 
12.31周二 研究data-juice对数据去冗余 然后再做数据评估
1.1周三  研究data-juice对数据去冗余  然后再做数据评估
1.2周四  研究data-juice对数据去冗余  然后再做数据评估

=============================================
1.3-1.4周五周六  分析问题解决问题 


BERT/GPT初筛：去除明显的低质量样本
Data-juice精筛：进行更细致的质量控制

设置合理的过滤阈值
第一轮（BERT/GPT）：可以相对宽松，建议保留60-70%
第二轮（Data-juice）：可以更严格，建议保留50-60%
预期最终保留1.5k-2k条高质量数据


=========================================================


1.对男问女答的数据 做处理
2.生成了一些男问女答的数据 男拓展话题幽默风趣邀约  明天对剩下的男问女答进行补充
3.尝试生成了女的比较高冷的回答 挺难的 然后也就俩条种子数据 我感觉挺好