看了你给我分享的第一篇知乎文章 看了不到1/4吧 真的让我受益匪浅的 1.prompt不是越长越好 要是长的话，可能会延长它的推理时间，因为在理解很长很复杂的prompt到生成响应花的时间就挺长 2.如果进行sft prompt要是很丰富都不一样可以不进行对loss mask 反正就得加mask  我没理解我该怎么加好 swift可以加嘛 3.明白了，广义上的模型幻觉和狭义上的模型幻觉 广义上的模型幻觉，我的理解就是，那些大厂再怎么做技术提升还是解决不了大模型的幻觉问题 只有通过外挂知识库或者调用工具函数得到缓解 ，狭义上的模型幻觉，那就是，自己调参方法没调会导致的幻觉问题4.明白了，目前工业界的AI模型对安全性的问题是怎么控制的 模型的输出有上下游的小模型或者词典进行拦截或是改写


1.数据配比  垂直比通用的=1：5 可能还需要加一些多轮对话的数据 说要占整体数据的30%-50%，按30算就行了 也可以=1：10 多轮对话的数据要是考虑的话， 
11.问一下 对instruct模型进行微调 角色对话数据：通用对话数据的比例大概是多少啊 5:5或3:7都行
2.你可以试一次只用自己的数据 训一次 多开一个机器 测试一下
3.关于system字段 长得有效才行 最终看测试集反馈来调整吧
这样：
浅关系 女生邀约 你是一名高情商海王，角色的特点是对女问男要幽默风趣高情商，对女生的要求巧妙回避。具体来说response 应该保持轻松愉快的语气，巧妙地转移话题或设置适度的距离，既不直接拒绝也不过分承诺。 
这样可以吧 有角色介绍和标签 但没对标签进行解释 
4.关于prompt 要有长有短 长数据还不能是字面意思的长 要有关键信息藏在开头/中间/结尾/ 防止模型偷懒 只有最前面 最后面的attention prompt不要单一 要多样化  answer多样性很重要 别重复同一句话
最关键的是***数据的形式要多样性不能让模型找到规律（模型会偷懒的），关键信息再prompt中的位置分布足够随机***
5.关于生产prompt 基于一些seed问题直接仿写prompt 用gpt4  或者看看开源sft数据 搜刮一下prompt就行 不要回答 实在不行自己写写prompt
6.关于比较困难的任务 要学会拆解 比如：让模型写一万字的爽文 看似很简单但给人都不一定能写出来 所以 prompt1.可以生成故事大纲 大纲包括****  prompt2.请基于给定的故事大纲，扩充内容，生成一篇不少于多少字的内容
7.关于answer 不在乎成本用gpt4 Claude3 在乎成本 可以本地部署qwen2.5-72b  deepseek_MOE  llama模型不行 中文能力差

2 模型微调
数据配比
对于角色扮演模型，通用数据集的配比通常可以在0%～50%。在某些情况下，完全不使用通用数据也是可行的。比如当训练的是单角色且 prompt 变化不大时，可以只用专有数据进行训练。然而，这样做会导致强烈的过拟合，会损害模型的通用能力。但从效果上来看，这种单角色的过拟合在特定的产品场景下可能表现得不错，这块就见仁见智了。我个人一般是采用 30% 比例的通用数据集，这个效果在业务上还可以。另外，角色扮演数据集最好能涵盖多种渠道，以保证多样性。同时要清楚的了解每个渠道的数据特点（比如哪个 os 多，哪个口语化，哪个逻辑好），结合基座模型的特性和最终效果，对数据配比进行适当调整。


lora微调参数

per_device_train_batch_size

gradient_accumulation_steps

learning_rate

num_train_epochs

warmup_ratio

bf16


