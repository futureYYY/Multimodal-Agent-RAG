# Multimodal Agent RAG (多模态 Agent RAG 系统)

## 1. 项目名称
**Multimodal Agent RAG** (多模态智能体检索增强生成系统)

## 2. 项目简介
本项目是一个基于 **Agentic Workflow (智能体工作流)** 的下一代多模态 RAG 系统。
*   **核心定位**：解决传统 RAG 无法有效处理图片内容、查询理解能力弱、召回准确率低的问题。
*   **核心优势**：
    *   **真·多模态**：不仅能“读”文字，还能“看”懂图片。支持 PDF/Word 图文自动提取与对齐，实现“以图搜图”和“图文混合问答”。
    *   **智能思考**：引入 LangGraph 构建 Agent 状态机，具备意图识别、查询改写、HyDE (假设性文档生成) 等高级推理能力。
    *   **精准召回**：采用“向量检索 + 关键词检索 + Cross-Encoder 重排序”的混合检索策略，大幅提升答案质量。
    *   **灵活部署**：原生支持本地化部署（Ollama），也支持接入火山引擎（豆包）等云端模型，数据安全可控。
*   **适用人群/场景**：适合企业构建私有知识库、个人知识管理、法律/金融/医疗等需要精准文档解析和问答的场景。

## 3. 快速开始

### 3.1 前置依赖
*   **Python**: 3.10+
*   **Node.js**: 18.0+
*   **Ollama** (可选，若使用本地模型): 请提前安装并下载 `qwen2.5` 等模型。

### 3.2 安装步骤

#### 后端 (Backend)
```bash
cd backend
# 1. 创建虚拟环境 (推荐)
conda create -n agent python=3.10
conda activate agent

# 2. 安装依赖
pip install -r requirements.txt
```

#### 前端 (Frontend)
```bash
cd frontend
# 1. 安装依赖
npm install
```

### 3.3 简单使用示例

**第一步：启动后端**
```bash
# 在 backend 目录下
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

**第二步：启动前端**
```bash
# 在 frontend 目录下
npm run dev
```

**第三步：访问系统**
打开浏览器访问 `http://localhost:3000`。

**第四步：模型配置 (关键)**
进入系统设置页面，配置模型参数：
*   **Embedding 模型 (推荐)**: `doubao-embedding-vision-251215` (火山引擎多模态模型，效果最佳)
*   **VLM 模型**: 可选择 `Doubao-Seed-1.8` 或本地 `qwen3-vl`。

**第五步：开始使用**
1.  在“知识库管理”页面上传 PDF/Word 文档。
2.  等待系统自动解析图文内容。
3.  进入“智能对话”，尝试提问：“这篇文章里的架构图是怎么画的？” 或 “总结一下文中提到的数据趋势”。

## 4. 核心功能详解

*   **多模态文档解析**: 
    *   自动提取 PDF 中的文本和图片，保留文档原本的图文对应关系。
    *   使用 VLM (视觉大模型) 对图片进行深度理解并生成描述索引。
*   **Agent 智能编排 (LangGraph)**:
    *   **意图识别**: 自动判断用户是在闲聊还是查资料。
    *   **查询改写**: 将用户的口语化问题改写为更精准的搜索关键词。
    *   **HyDE 增强**: 生成假设性答案以提升检索的相关性。
*   **混合检索与重排序**:
    *   结合向量相似度 (Dense) 和关键词匹配 (Sparse) 进行广度召回。
    *   使用 Cross-Encoder 模型对结果进行二次精排，剔除无关内容。

## 5. 配置说明
*   本项目设计为**开箱即用**，大部分配置已通过前端界面进行动态管理。
*   **模型配置**: 在前端“设置”页面即可切换 Ollama 本地模型或 OpenAI/火山引擎 API，无需修改后端代码配置文件。

## 6. 常见问题 (FAQ)
*   **Q: 前端页面无法打开？**
    *   A: 请确认 `npm run dev` 运行的端口是否为 3000，并检查防火墙设置。
*   **Q: 本地模型运行卡顿？**
    *   A: 推荐使用量化版本（如 q4_k_m），或确保显存充足（7B 模型建议 8GB+ 显存）。

## 7. 贡献指南
欢迎提交 Issue 和 Pull Request！
*   **分支管理**: 请基于 `main` 分支创建功能分支 `feature/your-feature`。
*   **提交规范**: 请使用 Conventional Commits 规范 (如 `feat: add new parser`)。

## 8. 许可证信息

本项目采用 **MIT License** 开源协议。完整协议文本请参阅 [LICENSE](LICENSE) 文件。

### 版权声明
Copyright (c) 2025 齐雨凡 (qiyufan)

> **核心说明**：任何人使用/修改/分享本项目代码时，必须保留上述版权声明，即明确本项目的原作者为 **齐雨凡 (qiyufan)**。

## 9. 联系方式
*   **邮箱**: 19917741015@163.com
*   **反馈**: 欢迎通过邮件或 GitHub Issues 反馈建议。
